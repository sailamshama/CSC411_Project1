{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "PURPOSE: \n",
    "To build a classifier using Linear Regression to distinguish images of two actors.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replace_labels(y,labels):\n",
    "    y_relabeled = np.copy(y)\n",
    "    for label in labels:\n",
    "        for index in np.where(y == label[0]):\n",
    "            np.put(y_relabeled, index, label[1])\n",
    "    return y_relabeled.astype(int)\n",
    "\n",
    "#change output labels to 0 and 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten_set(x):\n",
    "    #returned ndarray should have shape (N, M), where N = # pixels and M = # images\n",
    "    for i in range(x.shape[-1]):\n",
    "        flattened_image = x[...,i].flatten() \n",
    "        if i == 0:\n",
    "            x_flattened = flattened_image\n",
    "        else:\n",
    "            x_flattened = np.vstack((x_flattened, flattened_image))\n",
    "            \n",
    "    return x_flattened.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cost(x,y,theta):\n",
    "    #quadratic cost function\n",
    "    #x = np.vstack( (np.ones((1, x.shape[1])), x))\n",
    "    return np.sum( (y - np.dot(theta.T,x)) ** 2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dcost_dtheta(x,y,theta):\n",
    "    #x = np.vstack( (np.ones((1, x.shape[1])), x))\n",
    "    return -2*np.sum((y-np.dot(theta.T, x))*x, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grad_descent(cost, dcost_dtheta, x, y, init_theta, alpha,max_iter):\n",
    "    EPS = 1e-5   #EPS = 10**(-5)\n",
    "    prev_t = init_theta-10*EPS\n",
    "    t = init_theta.copy()\n",
    "    itr  = 1\n",
    " \n",
    "    while np.linalg.norm(t - prev_t) >  EPS and itr < max_iter:\n",
    "        prev_t = t.copy()\n",
    "        t -= alpha*dcost_dtheta(x, y, t)\n",
    "        if itr % 50 == 0:\n",
    "            print \"Iter\", itr\n",
    "            print \"t = (%.2f, %.2f, %.2f), cost(x) = %.2f\" % (t[0], t[1], t[2], cost(x, y, t)) \n",
    "            print \"Gradient: \", dcost_dtheta(x, y, t), \"\\n\"\n",
    "#           y_pred = pred_y(x,t)\n",
    "#            print(\"Performance: \",performance(y_pred,y_val))\n",
    "        itr += 1\n",
    "\n",
    "    \n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pred_y(x,theta):\n",
    "\n",
    "    #x = np.vstack((np.ones((1, x.shape[1])), x ))    \n",
    "    h_all = np.dot(theta.T,x)\n",
    "#    print(\"h(theta) for all images: \")\n",
    "#    print(h_all)\n",
    "    y_pred = np.ones(h_all.shape[0])\n",
    "    \n",
    "    for i in range(h_all.shape[0]):\n",
    "        h=h_all[i]\n",
    "        if h > 0.5:\n",
    "            y_pred[i] = 1\n",
    "        elif h < 0.5:\n",
    "            y_pred[i] = 0\n",
    "        else:\n",
    "            y_pred[i]=randint(0,1)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def performance(y_pred, y):\n",
    "    sum = 0.0\n",
    "    test_size = y.shape[0]\n",
    "    for i in range(test_size):\n",
    "        if y_pred[i] == y[i]:\n",
    "            sum +=1\n",
    "    return sum/test_size * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(2837499)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load data sets containing only 'Alec Baldwin' and 'Steve Carel'\n",
    "x_train = np.load(\"x_train0.npy\") \n",
    "y_train = np.load(\"y_train0.npy\")\n",
    "\n",
    "x_val = np.load(\"x_val0.npy\")\n",
    "y_val = np.load(\"y_val0.npy\")\n",
    "\n",
    "x_test = np.load(\"x_test0.npy\")\n",
    "y_test = np.load(\"y_test0.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = replace_labels(y_train, [(\"Alec Baldwin\",1), (\"Steve Carell\",0)])\n",
    "y_val = replace_labels(y_val, [(\"Alec Baldwin\",1), (\"Steve Carell\",0)])\n",
    "y_test = replace_labels(y_test, [(\"Alec Baldwin\",1), (\"Steve Carell\",0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = flatten_set(x_train) / 255.0\n",
    "x_val = flatten_set(x_val) / 255.0\n",
    "x_test = flatten_set(x_test) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#initialize from normal distribution\n",
    "pixel_inten_mean = np.mean(x_train)\n",
    "pixel_inten_std  = np.std(x_train)\n",
    "#change center to 0.5 and std to 0.2 or something\n",
    "theta0 = np.random.normal( 0, 0.2, x_train.shape[0]+1) #of dimension (1025,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_w_bias = np.vstack( (np.ones((1, x_train.shape[1])), x_train))\n",
    "x_val_w_bias = np.vstack( (np.ones((1, x_val.shape[1])), x_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "theta_complete = grad_descent(cost, dcost_dtheta, x_train_w_bias, y_train, theta0, 0.00001,30000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#theta for complete dataset\n",
    "np.save(\"theta_part3_complete.npy\",theta_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Part 4 : Obtaning thetas from training on data set of only 2 images per actor\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_small = np.load(\"x_train1.npy\") \n",
    "y_train_small = np.load(\"y_train1.npy\")\n",
    "\n",
    "x_train_small = flatten_set(x_train_small) / 255.0\n",
    "y_train_small = replace_labels(y_train_small, [(\"Alec Baldwin\",1), (\"Steve Carell\",0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pixel_inten_mean = np.mean(x_train_small)\n",
    "pixel_inten_std  = np.std(x_train_small)\n",
    "theta0 = np.random.normal( 0, 0, x_train_small.shape[0]+1) #of dimension (1025,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_small_w_bias = np.vstack( (np.ones((1, x_train_small.shape[1])), x_train_small))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 50\n",
      "x = (0.00, 0.00, 0.00), cost(x) = 0.98\n",
      "Gradient:  [-1.13695569 -0.13883805 -0.20568604 ..., -0.07405688 -0.18759982\n",
      " -1.10536329] \n",
      "\n",
      "Iter 100\n",
      "x = (0.00, 0.00, 0.00), cost(x) = 0.84\n",
      "Gradient:  [-0.25382162  0.05277619 -0.03106503 ...,  0.18371558  0.14943483\n",
      " -0.80037351] \n",
      "\n",
      "Iter 150\n",
      "x = (0.00, 0.00, 0.00), cost(x) = 0.79\n",
      "Gradient:  [ 0.01804717  0.11580846  0.02791909 ...,  0.24969464  0.23817691\n",
      " -0.69474113] \n",
      "\n",
      "Iter 200\n",
      "x = (0.00, 0.00, 0.00), cost(x) = 0.75\n",
      "Gradient:  [ 0.10114145  0.13861408  0.05064967 ...,  0.25752311  0.2515068\n",
      " -0.65102224] \n",
      "\n",
      "Iter 250\n",
      "x = (0.00, 0.00, 0.00), cost(x) = 0.72\n",
      "Gradient:  [ 0.12588767  0.14851452  0.06167908 ...,  0.2483701   0.24269027\n",
      " -0.62677135] \n",
      "\n",
      "Iter 300\n",
      "x = (0.00, -0.00, 0.00), cost(x) = 0.68\n",
      "Gradient:  [ 0.13255553  0.15398707  0.06863028 ...,  0.23486631  0.22807794\n",
      " -0.60886879] \n",
      "\n",
      "Iter 350\n",
      "x = (0.00, -0.00, 0.00), cost(x) = 0.65\n",
      "Gradient:  [ 0.13358399  0.15768854  0.07389676 ...,  0.22083931  0.21263271\n",
      " -0.59324849] \n",
      "\n",
      "Iter 400\n",
      "x = (0.00, -0.00, 0.00), cost(x) = 0.62\n",
      "Gradient:  [ 0.13282029  0.16047571  0.07825444 ...,  0.20740502  0.19780907\n",
      " -0.57864018] \n",
      "\n",
      "Iter 450\n",
      "x = (0.00, -0.00, 0.00), cost(x) = 0.60\n",
      "Gradient:  [ 0.13145891  0.16264671  0.08197688 ...,  0.19484763  0.1839848  -0.5646376 ] \n",
      "\n",
      "Iter 500\n",
      "x = (0.00, -0.00, 0.00), cost(x) = 0.57\n",
      "Gradient:  [ 0.12987485  0.1643244   0.08517976 ...,  0.1831994   0.17121105\n",
      " -0.55110213] \n",
      "\n",
      "Iter 550\n",
      "x = (0.00, -0.00, -0.00), cost(x) = 0.55\n",
      "Gradient:  [ 0.12818958  0.16557499  0.08792744 ...,  0.17241935  0.15944347\n",
      " -0.53797859] \n",
      "\n",
      "Iter 600\n",
      "x = (0.00, -0.00, -0.00), cost(x) = 0.52\n",
      "Gradient:  [ 0.12644578  0.16644483  0.09026611 ...,  0.16244794  0.14861306\n",
      " -0.52523838] \n",
      "\n",
      "Iter 650\n",
      "x = (0.00, -0.00, -0.00), cost(x) = 0.50\n",
      "Gradient:  [ 0.12466137  0.166972    0.09223414 ...,  0.15322372  0.13864773\n",
      " -0.5128618 ] \n",
      "\n",
      "Iter 700\n",
      "x = (0.00, -0.00, -0.00), cost(x) = 0.48\n",
      "Gradient:  [ 0.12284617  0.16719     0.09386552 ...,  0.1446881   0.1294785  -0.5008326 ] \n",
      "\n",
      "Iter 750\n",
      "x = (0.00, -0.00, -0.00), cost(x) = 0.46\n",
      "Gradient:  [ 0.1210071   0.16712914  0.09519103 ...,  0.13678657  0.12104117\n",
      " -0.48913619] \n",
      "\n",
      "Iter 800\n",
      "x = (0.00, -0.00, -0.00), cost(x) = 0.44\n",
      "Gradient:  [ 0.11914984  0.166817    0.0962388  ...,  0.12946882  0.11327646\n",
      " -0.47775909] \n",
      "\n",
      "Iter 850\n",
      "x = (0.00, -0.00, -0.00), cost(x) = 0.42\n",
      "Gradient:  [ 0.11727935  0.16627884  0.09703457 ...,  0.1226885   0.10612982\n",
      " -0.46668868] \n",
      "\n",
      "Iter 900\n",
      "x = (0.00, -0.00, -0.00), cost(x) = 0.41\n",
      "Gradient:  [ 0.11540003  0.16553776  0.09760193 ...,  0.11640301  0.0995511\n",
      " -0.45591312] \n",
      "\n",
      "Iter 950\n",
      "x = (0.00, -0.00, -0.00), cost(x) = 0.39\n",
      "Gradient:  [ 0.11351589  0.16461488  0.0979625  ...,  0.11057314  0.09349417\n",
      " -0.44542126] \n",
      "\n",
      "Iter 1000\n",
      "x = (0.00, -0.00, -0.00), cost(x) = 0.37\n",
      "Gradient:  [ 0.11163049  0.16352954  0.09813609 ...,  0.10516286  0.08791668\n",
      " -0.43520257] \n",
      "\n",
      "Iter 1050\n",
      "x = (0.00, -0.00, -0.00), cost(x) = 0.36\n",
      "Gradient:  [ 0.10974708  0.16229942  0.09814086 ...,  0.10013903  0.08277968\n",
      " -0.42524715] \n",
      "\n",
      "Iter 1100\n",
      "x = (0.00, -0.00, -0.00), cost(x) = 0.34\n",
      "Gradient:  [ 0.10786855  0.16094069  0.09799342 ...,  0.09547116  0.07804738\n",
      " -0.41554561] \n",
      "\n",
      "Iter 1150\n",
      "x = (0.00, -0.00, -0.00), cost(x) = 0.33\n",
      "Gradient:  [ 0.10599753  0.15946812  0.09770901 ...,  0.09113123  0.07368689\n",
      " -0.40608911] \n",
      "\n",
      "Iter 1200\n",
      "x = (0.00, -0.00, -0.00), cost(x) = 0.32\n",
      "Gradient:  [ 0.10413634  0.1578952   0.09730157 ...,  0.08709346  0.06966799\n",
      " -0.39686924] \n",
      "\n",
      "Iter 1250\n",
      "x = (0.00, -0.00, -0.00), cost(x) = 0.31\n",
      "Gradient:  [ 0.10228709  0.15623426  0.09678384 ...,  0.08333414  0.06596291\n",
      " -0.38787807] \n",
      "\n",
      "Iter 1300\n",
      "x = (0.00, -0.00, -0.00), cost(x) = 0.29\n",
      "Gradient:  [ 0.10045162  0.15449654  0.09616751 ...,  0.07983148  0.06254613\n",
      " -0.37910805] \n",
      "\n",
      "Iter 1350\n",
      "x = (0.00, -0.00, -0.00), cost(x) = 0.28\n",
      "Gradient:  [ 0.09863159  0.1526923   0.09546325 ...,  0.07656544  0.05939419\n",
      " -0.37055204] \n",
      "\n",
      "Iter 1400\n",
      "x = (0.00, -0.00, -0.00), cost(x) = 0.27\n",
      "Gradient:  [ 0.09682847  0.15083088  0.09468081 ...,  0.07351755  0.05648555\n",
      " -0.36220323] \n",
      "\n",
      "Iter 1450\n",
      "x = (0.00, -0.00, -0.00), cost(x) = 0.26\n",
      "Gradient:  [ 0.09504356  0.14892081  0.09382913 ...,  0.07067087  0.0538004\n",
      " -0.35405515] \n",
      "\n",
      "Iter 1500\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.25\n",
      "Gradient:  [ 0.09327798  0.14696984  0.09291634 ...,  0.0680098   0.05132056\n",
      " -0.34610165] \n",
      "\n",
      "Iter 1550\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.24\n",
      "Gradient:  [ 0.09153272  0.14498503  0.0919499  ...,  0.06551998  0.04902931\n",
      " -0.33833686] \n",
      "\n",
      "Iter 1600\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.23\n",
      "Gradient:  [ 0.08980864  0.14297278  0.09093658 ...,  0.06318821  0.04691129\n",
      " -0.33075516] \n",
      "\n",
      "Iter 1650\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.22\n",
      "Gradient:  [ 0.08810648  0.14093892  0.0898826  ...,  0.06100235  0.04495239\n",
      " -0.32335122] \n",
      "\n",
      "Iter 1700\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.21\n",
      "Gradient:  [ 0.08642688  0.13888873  0.0887936  ...,  0.05895122  0.04313965\n",
      " -0.31611992] \n",
      "\n",
      "Iter 1750\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.20\n",
      "Gradient:  [ 0.08477034  0.13682699  0.08767472 ...,  0.05702455  0.04146116\n",
      " -0.30905636] \n",
      "\n",
      "Iter 1800\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.20\n",
      "Gradient:  [ 0.08313733  0.13475805  0.08653066 ...,  0.05521287  0.03990597\n",
      " -0.30215586] \n",
      "\n",
      "Iter 1850\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.19\n",
      "Gradient:  [ 0.08152818  0.13268582  0.08536566 ...,  0.05350749  0.03846405\n",
      " -0.29541393] \n",
      "\n",
      "Iter 1900\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.18\n",
      "Gradient:  [ 0.0799432   0.13061383  0.08418362 ...,  0.05190039  0.03712614\n",
      " -0.28882625] \n",
      "\n",
      "Iter 1950\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.17\n",
      "Gradient:  [ 0.07838258  0.12854528  0.08298805 ...,  0.05038421  0.03588379\n",
      " -0.28238869] \n",
      "\n",
      "Iter 2000\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.17\n",
      "Gradient:  [ 0.07684648  0.12648303  0.08178214 ...,  0.04895216  0.03472918\n",
      " -0.27609726] \n",
      "\n",
      "Iter 2050\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.16\n",
      "Gradient:  [ 0.075335    0.12442966  0.08056879 ...,  0.04759799  0.03365518\n",
      " -0.26994815] \n",
      "\n",
      "Iter 2100\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.15\n",
      "Gradient:  [ 0.07384819  0.12238747  0.07935063 ...,  0.04631597  0.03265521\n",
      " -0.26393766] \n",
      "\n",
      "Iter 2150\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.15\n",
      "Gradient:  [ 0.07238606  0.12035853  0.07813002 ...,  0.0451008   0.03172324\n",
      " -0.25806224] \n",
      "\n",
      "Iter 2200\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.14\n",
      "Gradient:  [ 0.07094855  0.11834468  0.0769091  ...,  0.0439476   0.03085372\n",
      " -0.25231848] \n",
      "\n",
      "Iter 2250\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.14\n",
      "Gradient:  [ 0.0695356   0.11634755  0.0756898  ...,  0.0428519   0.03004156\n",
      " -0.24670306] \n",
      "\n",
      "Iter 2300\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.13\n",
      "Gradient:  [ 0.0681471   0.11436858  0.07447387 ...,  0.04180956  0.0292821\n",
      " -0.24121281] \n",
      "\n",
      "Iter 2350\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.13\n",
      "Gradient:  [ 0.06678292  0.11240907  0.07326286 ...,  0.04081677  0.02857104\n",
      " -0.23584464] \n",
      "\n",
      "Iter 2400\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.12\n",
      "Gradient:  [ 0.06544288  0.11047012  0.07205816 ...,  0.03987003  0.02790444\n",
      " -0.23059556] \n",
      "\n",
      "Iter 2450\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.12\n",
      "Gradient:  [ 0.06412681  0.10855271  0.07086104 ...,  0.03896612  0.02727869\n",
      " -0.22546271] \n",
      "\n",
      "Iter 2500\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.11\n",
      "Gradient:  [ 0.0628345   0.10665768  0.06967261 ...,  0.03810205  0.02669046\n",
      " -0.22044328] \n",
      "\n",
      "Iter 2550\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.11\n",
      "Gradient:  [ 0.06156571  0.10478578  0.06849386 ...,  0.03727509  0.02613672\n",
      " -0.21553457] \n",
      "\n",
      "Iter 2600\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.10\n",
      "Gradient:  [ 0.06032022  0.10293762  0.06732567 ...,  0.0364827   0.02561465\n",
      " -0.21073397] \n",
      "\n",
      "Iter 2650\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.10\n",
      "Gradient:  [ 0.05909775  0.10111372  0.06616881 ...,  0.03572256  0.0251217\n",
      " -0.20603893] \n",
      "\n",
      "Iter 2700\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.10\n",
      "Gradient:  [ 0.05789805  0.09931451  0.06502397 ...,  0.03499252  0.02465551\n",
      " -0.20144698] \n",
      "\n",
      "Iter 2750\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.09\n",
      "Gradient:  [ 0.05672083  0.09754036  0.06389174 ...,  0.0342906   0.02421392\n",
      " -0.19695574] \n",
      "\n",
      "Iter 2800\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.09\n",
      "Gradient:  [ 0.05556581  0.09579153  0.06277265 ...,  0.03361496  0.02379494\n",
      " -0.19256288] \n",
      "\n",
      "Iter 2850\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.09\n",
      "Gradient:  [ 0.05443269  0.09406823  0.06166713 ...,  0.03296393  0.02339676\n",
      " -0.18826614] \n",
      "\n",
      "Iter 2900\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.08\n",
      "Gradient:  [ 0.05332117  0.09237063  0.06057556 ...,  0.03233594  0.0230177\n",
      " -0.18406333] \n",
      "\n",
      "Iter 2950\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.08\n",
      "Gradient:  [ 0.05223094  0.09069881  0.05949828 ...,  0.03172955  0.02265623\n",
      " -0.17995231] \n",
      "\n",
      "Iter 3000\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.08\n",
      "Gradient:  [ 0.05116168  0.08905281  0.05843553 ...,  0.03114345  0.02231096\n",
      " -0.17593101] \n",
      "\n",
      "Iter 3050\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.07\n",
      "Gradient:  [ 0.05011309  0.08743265  0.05738755 ...,  0.03057639  0.02198058\n",
      " -0.1719974 ] \n",
      "\n",
      "Iter 3100\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.07\n",
      "Gradient:  [ 0.04908484  0.08583829  0.05635451 ...,  0.03002726  0.02166393\n",
      " -0.16814951] \n",
      "\n",
      "Iter 3150\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.07\n",
      "Gradient:  [ 0.04807661  0.08426964  0.05533653 ...,  0.029495    0.02135991\n",
      " -0.16438544] \n",
      "\n",
      "Iter 3200\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.06\n",
      "Gradient:  [ 0.04708809  0.08272659  0.05433372 ...,  0.02897865  0.02106754\n",
      " -0.16070332] \n",
      "\n",
      "Iter 3250\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.06\n",
      "Gradient:  [ 0.04611895  0.08120902  0.05334614 ...,  0.0284773   0.02078591\n",
      " -0.15710131] \n",
      "\n",
      "Iter 3300\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.06\n",
      "Gradient:  [ 0.04516886  0.07971676  0.05237381 ...,  0.02799013  0.02051418\n",
      " -0.15357767] \n",
      "\n",
      "Iter 3350\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.06\n",
      "Gradient:  [ 0.04423752  0.07824961  0.05141676 ...,  0.02751637  0.0202516\n",
      " -0.15013064] \n",
      "\n",
      "Iter 3400\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.06\n",
      "Gradient:  [ 0.04332459  0.07680738  0.05047495 ...,  0.02705531  0.01999745\n",
      " -0.14675856] \n",
      "\n",
      "Iter 3450\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.05\n",
      "Gradient:  [ 0.04242976  0.07538984  0.04954835 ...,  0.02660629  0.0197511\n",
      " -0.14345977] \n",
      "\n",
      "Iter 3500\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.05\n",
      "Gradient:  [ 0.04155272  0.07399674  0.04863689 ...,  0.0261687   0.01951196\n",
      " -0.14023267] \n",
      "\n",
      "Iter 3550\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.05\n",
      "Gradient:  [ 0.04069315  0.07262783  0.04774051 ...,  0.02574197  0.0192795\n",
      " -0.13707569] \n",
      "\n",
      "Iter 3600\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.05\n",
      "Gradient:  [ 0.03985073  0.07128284  0.0468591  ...,  0.02532558  0.01905322\n",
      " -0.13398731] \n",
      "\n",
      "Iter 3650\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.05\n",
      "Gradient:  [ 0.03902517  0.06996149  0.04599255 ...,  0.02491903  0.01883267\n",
      " -0.13096603] \n",
      "\n",
      "Iter 3700\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.04\n",
      "Gradient:  [ 0.03821614  0.06866348  0.04514075 ...,  0.02452188  0.01861745\n",
      " -0.1280104 ] \n",
      "\n",
      "Iter 3750\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.04\n",
      "Gradient:  [ 0.03742336  0.06738854  0.04430356 ...,  0.02413369  0.01840717 -0.125119  ] \n",
      "\n",
      "Iter 3800\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.04\n",
      "Gradient:  [ 0.03664652  0.06613634  0.04348085 ...,  0.02375408  0.01820149\n",
      " -0.12229043] \n",
      "\n",
      "Iter 3850\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.04\n",
      "Gradient:  [ 0.03588533  0.06490659  0.04267246 ...,  0.02338269  0.0180001\n",
      " -0.11952334] \n",
      "\n",
      "Iter 3900\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.04\n",
      "Gradient:  [ 0.03513949  0.06369896  0.04187823 ...,  0.02301915  0.0178027\n",
      " -0.11681639] \n",
      "\n",
      "Iter 3950\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.04\n",
      "Gradient:  [ 0.03440871  0.06251314  0.04109799 ...,  0.02266317  0.01760903\n",
      " -0.1141683 ] \n",
      "\n",
      "Iter 4000\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.03\n",
      "Gradient:  [ 0.03369272  0.06134882  0.04033159 ...,  0.02231445  0.01741886\n",
      " -0.1115778 ] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 4050\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.03\n",
      "Gradient:  [ 0.03299122  0.06020566  0.03957884 ...,  0.02197269  0.01723196\n",
      " -0.10904364] \n",
      "\n",
      "Iter 4100\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.03\n",
      "Gradient:  [ 0.03230395  0.05908336  0.03883957 ...,  0.02163766  0.01704813\n",
      " -0.10656463] \n",
      "\n",
      "Iter 4150\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.03\n",
      "Gradient:  [ 0.03163063  0.05798157  0.03811358 ...,  0.02130909  0.01686718\n",
      " -0.10413956] \n",
      "\n",
      "Iter 4200\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.03\n",
      "Gradient:  [ 0.03097099  0.05689999  0.03740071 ...,  0.02098677  0.01668896\n",
      " -0.10176729] \n",
      "\n",
      "Iter 4250\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.03\n",
      "Gradient:  [ 0.03032477  0.05583828  0.03670075 ...,  0.02067048  0.01651331\n",
      " -0.09944669] \n",
      "\n",
      "Iter 4300\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.03\n",
      "Gradient:  [ 0.02969171  0.05479612  0.03601353 ...,  0.02036002  0.01634009\n",
      " -0.09717665] \n",
      "\n",
      "Iter 4350\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.03\n",
      "Gradient:  [ 0.02907156  0.0537732   0.03533884 ...,  0.0200552   0.01616917\n",
      " -0.09495608] \n",
      "\n",
      "Iter 4400\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.03\n",
      "Gradient:  [ 0.02846405  0.0527692   0.0346765  ...,  0.01975585  0.01600044\n",
      " -0.09278393] \n",
      "\n",
      "Iter 4450\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.02\n",
      "Gradient:  [ 0.02786895  0.05178379  0.03402632 ...,  0.01946179  0.01583378\n",
      " -0.09065916] \n",
      "\n",
      "Iter 4500\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.02\n",
      "Gradient:  [ 0.027286    0.05081666  0.0333881  ...,  0.01917287  0.01566911\n",
      " -0.08858076] \n",
      "\n",
      "Iter 4550\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.02\n",
      "Gradient:  [ 0.02671498  0.0498675   0.03276166 ...,  0.01888894  0.01550634\n",
      " -0.08654774] \n",
      "\n",
      "Iter 4600\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.02\n",
      "Gradient:  [ 0.02615565  0.04893601  0.0321468  ...,  0.01860987  0.01534539\n",
      " -0.08455913] \n",
      "\n",
      "Iter 4650\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.02\n",
      "Gradient:  [ 0.02560777  0.04802187  0.03154333 ...,  0.01833551  0.01518618\n",
      " -0.08261398] \n",
      "\n",
      "Iter 4700\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.02\n",
      "Gradient:  [ 0.02507111  0.04712478  0.03095106 ...,  0.01806575  0.01502865\n",
      " -0.08071136] \n",
      "\n",
      "Iter 4750\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.02\n",
      "Gradient:  [ 0.02454547  0.04624444  0.03036981 ...,  0.01780045  0.01487274\n",
      " -0.07885037] \n",
      "\n",
      "Iter 4800\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.02\n",
      "Gradient:  [ 0.0240306   0.04538056  0.02979939 ...,  0.01753952  0.0147184\n",
      " -0.07703011] \n",
      "\n",
      "Iter 4850\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.02\n",
      "Gradient:  [ 0.02352631  0.04453284  0.02923961 ...,  0.01728284  0.01456556\n",
      " -0.07524973] \n",
      "\n",
      "Iter 4900\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.02\n",
      "Gradient:  [ 0.02303239  0.043701    0.02869029 ...,  0.01703031  0.0144142\n",
      " -0.07350836] \n",
      "\n",
      "Iter 4950\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.02\n",
      "Gradient:  [ 0.02254861  0.04288474  0.02815125 ...,  0.01678182  0.01426427\n",
      " -0.07180517] \n",
      "\n",
      "Iter 5000\n",
      "x = (-0.00, -0.00, -0.00), cost(x) = 0.02\n",
      "Gradient:  [ 0.02207478  0.0420838   0.02762231 ...,  0.0165373   0.01411573\n",
      " -0.07013935] \n",
      "\n",
      "Iter 5050\n",
      "x = (-0.00, -0.01, -0.00), cost(x) = 0.02\n",
      "Gradient:  [ 0.02161071  0.04129788  0.02710328 ...,  0.01629665  0.01396854\n",
      " -0.06851011] \n",
      "\n",
      "Iter 5100\n",
      "x = (-0.00, -0.01, -0.00), cost(x) = 0.01\n",
      "Gradient:  [ 0.02115619  0.04052672  0.02659401 ...,  0.01605978  0.01382268\n",
      " -0.06691665] \n",
      "\n",
      "Iter 5150\n",
      "x = (-0.00, -0.01, -0.00), cost(x) = 0.01\n",
      "Gradient:  [ 0.02071103  0.03977006  0.0260943  ...,  0.01582661  0.01367813\n",
      " -0.06535823] \n",
      "\n",
      "Iter 5200\n",
      "x = (-0.00, -0.01, -0.00), cost(x) = 0.01\n",
      "Gradient:  [ 0.02027505  0.03902761  0.02560399 ...,  0.01559707  0.01353484\n",
      " -0.06383408] \n",
      "\n",
      "Iter 5250\n",
      "x = (-0.00, -0.01, -0.00), cost(x) = 0.01\n",
      "Gradient:  [ 0.01984806  0.03829913  0.02512291 ...,  0.01537108  0.0133928\n",
      " -0.06234348] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "theta_small = grad_descent(cost, dcost_dtheta, x_train_small_w_bias, y_train_small, theta0, 0.00001,30000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"theta_part3_small.npy\",theta_small)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CSC411_py2",
   "language": "python",
   "name": "csc411_py2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
